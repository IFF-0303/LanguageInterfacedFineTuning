<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks</title>
  <link rel="icon" type="image/x-icon" href="static/images/lift_logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bar_plot.css">
  <link rel="stylesheet" href="static/css/followup_work.css">
  <link rel="stylesheet" href="static/css/my_slider.css">
  
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script> 
  <script src="static/js/heatmap.js"></script>
  <script defer src="static/js/bar_plot.js"></script>
  <script defer src="static/js/my_slider.js"></script>
  <script defer src="static/js/line_plot.js"></script>
</head>
<body>

  <nav class="nav-wrapper">
    <div class="nav-container">
        <ul class="nav-links">
            <li><a href="#abstract">Abstract</a></li>
            <li><a href="#tasks">Tasks</a></li>
            <li><a href="#properties">Properties</a></li>
            <li><a href="#improvements">Improvements</a></li>
            <li><a href="#spotlights">Spotlights</a></li>
            <li><a href="#poster">Poster</a></li>
            <li><a href="#BibTeX">BibTeX</a></li>
        </ul>
    </div>
</nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tuanqdinh.com/" target="_blank">Tuan Dinh</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://yzeng58.github.io" target="_blank">Yuchen Zeng</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://ruisu516.github.io/" target="_blank">Ruisu Zhang</a>,</span>
                  <span class="author-block">
                    <a href="https://myhakureimu.github.io/" target="_blank">Ziqian Lin</a>,</span>
                  <span class="author-block">
                    <a href="https://gira.dev/" target="_blank">Michael Gira</a>,</span>
                  <span class="author-block">
                    <a href="https://shashankrajput.github.io/" target="_blank">Shashank Rajput</a>,</span>
                  <span class="author-block">
                    <a href="https://itml.yonsei.ac.kr/professor" target="_blank">Jy-yong Sohn</a>,</span>
                  <span class="author-block">
                    <a href="https://papail.io/" target="_blank">Dimitris Papailiopoulos</a>,</span>
                  <span class="author-block">
                    <a href="https://kangwooklee.com/aboutme/" target="_blank">Kangwook Lee</a></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Wisconsin-Madison<br>NeurIPS 2022</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Denotes equal contribution. Author order is alphabetical.</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2206.06565" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://neurips.cc/virtual/2022/poster/54500" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser" style="margin-top: -3rem;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/lift_demo.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        A high-level illustration of the LIFT framework. 
        LIFT has four steps: (i) converting the dataset into sentences, (ii) fine-tuning the pretrained LLMs (e.g., GPT) on the obtained sentences, (iii) generating predictions, and (iv) converting the predictions back to the original data format. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->


<!-- Paper abstract -->
<section class="section hero is-light" id="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Fine-tuning pretrained language models (LMs) without making any architectural changes has become a norm for learning various language downstream tasks. However, for non-language downstream tasks, a common practice is to employ task-specific designs for input, output layers, and loss functions. For instance, it is possible to fine-tune an LM into an MNIST classifier by replacing the word embedding layer with an image patch embedding layer, the word token output layer with a 10-way output layer, and the word prediction loss with a 10-way classification loss, respectively. A natural question arises: Can LM fine-tuning solve non-language downstream tasks without changing the model architecture or loss function? To answer this, we propose Language-Interfaced Fine-Tuning (LIFT) and study its efficacy and limitations by conducting an extensive empirical study on a suite of non-language classification and regression tasks. LIFT does not make any changes to the model architecture or loss function, and it solely relies on the natural language interface, enabling "no-code machine learning with LMs." We find that LIFT performs comparably well across a wide range of low-dimensional classification and regression tasks, matching the performances of the best baselines in many cases, especially for the classification tasks. We also report experimental results on the fundamental properties of LIFT, including inductive bias, robustness, and sample complexity. We also analyze the effect of pretraining on LIFT and a few properties/techniques specific to LIFT, e.g., context-aware learning via appropriate prompting, calibrated predictions, data generation, and two-stage fine-tuning. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image carousel -->
<section class="hero is-small" id="tasks">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">One Model, Many Tasks</h2>

  <!-- Navigation dots -->
  <div class="carousel-nav">
    <div class="nav-buttons">
      <button class="nav-button active">Tabular Regression</button>
      <button class="nav-button">Tabular Classification</button>
      <button class="nav-button">Image Classification</button>
      <button class="nav-button">Image Generation</button>
    </div>
  </div>
      <div class="carousel-container">
        <div class="carousel-track">
          
          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <img src="static/images/tabular_regression.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                LIFT for <b>Tabular Regression</b>
              </h2>
            </div>
          </div>

          <div class="carousel-slide">
            <div class="heatmap-container" id="heatmapContainer">
              <!-- Heatmap will be inserted here -->
            </div>
            <div class="legend">
              <span>0%</span>
              <div class="legend-gradient"></div>
              <span>100%</span>
            </div>

            <h2 class="subtitle has-text-centered">
              Heatmap of model performances across OpenML datasets
            </h2>
            <p class="content">
              The heatmap shows performance comparisons between different models across various OpenML datasets. 
              Darker blue indicates higher accuracy. Hover over cells to see exact accuracy values and standard deviations.
            </p>
          </div>

          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <img src="static/images/image_classification.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                LIFT for <b>Image Classification</b>
              </h2>
              <div class="heatmap-container" id="imageHeatmapContainer">
                <!-- Image data heatmap will be inserted here -->
              </div>
              <div class="legend">
                <span>0%</span>
                <div class="legend-gradient"></div>
                <span>100%</span>
              </div>
            </div>
          </div>

          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <img src="static/images/image_generation.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                LIFT for <b>Image Generation</b>
              </h2>
            </div>
          </div>
          
        </div>
      </div>
  
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero is-small is-light" id="properties">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">Properties of LIFT</h2>

  <!-- Navigation dots -->
  <div class="carousel-nav">
    <div class="nav-buttons">
      <button class="nav-button active">Fine-tuning vs. ICL</button>
      <button class="nav-button">Pretraining Effect</button>
      <button class="nav-button">Robustness</button>
      <button class="nav-button">Benefits of Context</button>
    </div>
  </div>
      <div class="carousel-container">
        <div class="carousel-track">
          
          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <h2 class="title is-3">Language-Interfaced Learning: Fine-Tuning versus In-Context Learning</h2>
      
              <canvas id="liicl"></canvas>
              
              
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                Comparison of accuracies between ICL and fine-tuning with LIFT on OpenML datasets.
              </h2>
              <p>
                "LIFT/Full-Data" and "LIFT/Subset" represent LIFT on the full dataset and its subset used correspondingly in the ICL setting (number of prompts). Here, the size of the subset is chosen to satisfy the LMs' context length. Overall, LIFT/GPTs on full data achieve the best performances. However, when using the same number of samples, LIFT and ICL are more comparable in most cases. Note that both methods may be worse than Majority Classifier due to the limited training data in some cases.
              </p>
            </div>
          </div>

          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
                <h2 class="title is-3">Model Performance Comparison</h2>
                <canvas id="modelComparisonChart"></canvas>
                <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                    Comparison of accuracies between different model variants
                </h2>
                <p>
                    Performance comparison across different LIFT variants and baselines. LIFT with GPT-3 and GPT-J achieve the best performance, while random initialization (Rand-GPT-J) performs poorly, demonstrating the importance of pre-training.
                </p>
            </div>
        </div>
          
          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <h2 class="title is-3">PGD Attack Results</h2>
              <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; width: 100%; max-width: 1200px;">
                <div style="width: 100%;">
                  <canvas id="pgdChart1"></canvas>
                </div>
                <div style="width: 100%;">
                  <canvas id="pgdChart2"></canvas>
                </div>
                <div style="width: 100%;">
                  <canvas id="pgdChart3"></canvas>
                </div>
                <div style="width: 100%;">
                  <canvas id="pgdChart4"></canvas>
                </div>
              </div>
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                PGD Attack Results on Different Models and Epsilon Values
              </h2>
              <p>
                Comparison of model robustness under PGD attacks with varying epsilon values. The plots show accuracy degradation for LxNet-S, MLP, and LIFT/GPT-3 models under different attack strengths.
              </p>
            </div>
          </div>

          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <h2 class="title is-3">Language-Interfaced Learning: Fine-Tuning versus In-Context Learning</h2>
      
              <canvas id="context"></canvas>
              
              
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                Comparison of accuracies between ICL and fine-tuning with LIFT on OpenML datasets.
              </h2>
              <p>
                "LIFT/Full-Data" and "LIFT/Subset" represent LIFT on the full dataset and its subset used correspondingly in the ICL setting (number of prompts). Here, the size of the subset is chosen to satisfy the LMs' context length. Overall, LIFT/GPTs on full data achieve the best performances. However, when using the same number of samples, LIFT and ICL are more comparable in most cases. Note that both methods may be worse than Majority Classifier due to the limited training data in some cases.
              </p>
            </div>
          </div>

        </div>
      </div>
  
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero is-small" id="improvements">
  <div class="hero-body">
    <div class="container">

      <h2 class="title is-3">Improvements</h2>

  <!-- Navigation dots -->
  <div class="carousel-nav">
    <div class="nav-buttons">
      <button class="nav-button active">Data Augmentation</button>
    </div>
  </div>
      <div class="carousel-container">
        <div class="carousel-track">
          

          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <h2 class="title is-3">Effect of Data Augmentation</h2>
      
              <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; width: 100%; max-width: 1200px;">
                <div style="width: 100%;">
                  <canvas id="dataAugmentationChart1"></canvas>
                </div>
                <div style="width: 100%;">
                  <canvas id="dataAugmentationChart2"></canvas>
                </div>
              </div>
              
            </div>
          </div>

        </div>
      </div>
  
    </div>
  </div>
</section>

<section class="hero is-small" id="key-points">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Building on Our Research: Spotlights</h2>
      
      <div class="columns is-centered">
        <div class="column is-10">
          <!-- First point -->
          <div class="box highlight-box">
            <div class="columns is-vcentered">
              <div class="column is-1">
                <span class="icon is-large has-text-primary">
                  <i class="fas fa-flask fa-2x"></i>
                </span>
              </div>
              <div class="column">
                <div class="highlight-content">
                  <span class="highlight-title">Predictive Chemistry</span>
                  <p>Leveraging large language models for predictive chemistry. <a href="https://www.nature.com/articles/s42256-023-00788-1">Learn more</a></p>
                </div>
              </div>
            </div>
          </div>

          <!-- Second point -->
          <div class="box highlight-box">
            <div class="columns is-vcentered">
              <div class="column is-1">
                <span class="icon is-large has-text-primary">
                  <i class="fas fa-chart-line fa-2x"></i>
                </span>
              </div>
              <div class="column">
                <div class="highlight-content">
                  <span class="highlight-title">Competitive Performance</span>
                  <p>Achieves comparable results to specialized models across various classification and regression tasks.</p>
                </div>
              </div>
            </div>
          </div>

          <!-- Third point -->
          <div class="box highlight-box">
            <div class="columns is-vcentered">
              <div class="column is-1">
                <span class="icon is-large has-text-primary">
                  <i class="fas fa-brain fa-2x"></i>
                </span>
              </div>
              <div class="column">
                <div class="highlight-content">
                  <span class="highlight-title">Versatile Applications</span>
                  <p>Successfully handles diverse tasks from tabular data to image classification through language-based interfaces.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container content">
      <h2 class="title">Cite Us</h2>
      <pre><code>
        @inproceedings{tuan_zeng_2022_lift,
          author = {Dinh, Tuan and Zeng, Yuchen and Zhang, Ruisu and Lin, Ziqian and Gira, Michael and Rajput, Shashank and Sohn, Jy-yong and Papailiopoulos, Dimitris and Lee, Kangwook},
          booktitle = {Advances in Neural Information Processing Systems},
          pages = {11763--11784},
          title = {LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks},
          volume = {35},
          year = {2022}
         }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page, and further updated by <a href="https://yzeng58.github.io" target="_blank">Yuchen Zeng</a>.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
