<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks</title>
  <link rel="icon" type="image/x-icon" href="static/images/lift_logo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/bulma/0.9.4/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/liicl.css">
  <link rel="stylesheet" href="static/css/followup_work.css">
  <link rel="stylesheet" href="static/css/my_slider.css">
  
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script> 
  <script src="static/js/tabular_classification.js"></script>
  <script defer src="static/js/liicl.js"></script>
  <script defer src="static/js/my_slider.js"></script>
</head>
<body>

  <nav class="nav-wrapper">
    <div class="nav-container">
        <ul class="nav-links">
            <li><a href="#abstract">Abstract</a></li>
            <li><a href="#tasks">Tasks</a></li>
            <li><a href="#comparison">Comparison</a></li>
            <li><a href="#performance">Performance</a></li>
            <li><a href="#spotlights">Spotlights</a></li>
            <li><a href="#poster">Poster</a></li>
            <li><a href="#BibTeX">BibTeX</a></li>
        </ul>
    </div>
</nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://tuanqdinh.com/" target="_blank">Tuan Dinh</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://yzeng58.github.io" target="_blank">Yuchen Zeng</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="https://ruisu516.github.io/" target="_blank">Ruisu Zhang</a>,</span>
                  <span class="author-block">
                    <a href="https://myhakureimu.github.io/" target="_blank">Ziqian Lin</a>,</span>
                  <span class="author-block">
                    <a href="https://gira.dev/" target="_blank">Michael Gira</a>,</span>
                  <span class="author-block">
                    <a href="https://shashankrajput.github.io/" target="_blank">Shashank Rajput</a>,</span>
                  <span class="author-block">
                    <a href="https://itml.yonsei.ac.kr/professor" target="_blank">Jy-yong Sohn</a>,</span>
                  <span class="author-block">
                    <a href="https://papail.io/" target="_blank">Dimitris Papailiopoulos</a>,</span>
                  <span class="author-block">
                    <a href="https://kangwooklee.com/aboutme/" target="_blank">Kangwook Lee</a></span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">University of Wisconsin-Madison<br>NeurIPS 2022</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Denotes equal contribution. Author order is alphabetical.</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2206.06565" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>


                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/UW-Madison-Lee-Lab/LanguageInterfacedFineTuning" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <span class="link-block">
                  <a href="https://neurips.cc/virtual/2022/poster/54500" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser video-->
<section class="hero teaser" style="margin-top: -3rem;">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/lift_demo.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        A high-level illustration of the LIFT framework. LIFT has a two-phase procedure: (1) converting the dataset into sentences and (2) fine-tuning the pretrained LLMs (e.g., GPT) on the obtained sentences. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->


<!-- Paper abstract -->
<section class="section hero is-light" id="abstract">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Fine-tuning pretrained language models (LMs) without making any architectural changes has become a norm for learning various language downstream tasks. However, for non-language downstream tasks, a common practice is to employ task-specific designs for input, output layers, and loss functions. For instance, it is possible to fine-tune an LM into an MNIST classifier by replacing the word embedding layer with an image patch embedding layer, the word token output layer with a 10-way output layer, and the word prediction loss with a 10-way classification loss, respectively. A natural question arises: Can LM fine-tuning solve non-language downstream tasks without changing the model architecture or loss function? To answer this, we propose Language-Interfaced Fine-Tuning (LIFT) and study its efficacy and limitations by conducting an extensive empirical study on a suite of non-language classification and regression tasks. LIFT does not make any changes to the model architecture or loss function, and it solely relies on the natural language interface, enabling "no-code machine learning with LMs." We find that LIFT performs comparably well across a wide range of low-dimensional classification and regression tasks, matching the performances of the best baselines in many cases, especially for the classification tasks. We also report experimental results on the fundamental properties of LIFT, including inductive bias, robustness, and sample complexity. We also analyze the effect of pretraining on LIFT and a few properties/techniques specific to LIFT, e.g., context-aware learning via appropriate prompting, calibrated predictions, data generation, and two-stage fine-tuning. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Image carousel -->
<section class="hero is-small" id="tasks">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <!-- Add this where you want the carousel to appear -->
      <div class="carousel-container">
        <div class="carousel-track">
          <!-- Original content slide -->
          <div class="carousel-slide">
            <div class="heatmap-container" id="heatmapContainer">
              <!-- Heatmap will be inserted here -->
            </div>
            <div class="legend">
              <span>0%</span>
              <div class="legend-gradient"></div>
              <span>100%</span>
            </div>

            <h2 class="subtitle has-text-centered">
              Heatmap of model performances across OpenML datasets
            </h2>
            <p class="content">
              The heatmap shows performance comparisons between different models across various OpenML datasets. 
              Darker blue indicates higher accuracy. Hover over cells to see exact accuracy values and standard deviations.
            </p>
          </div>
          
          <!-- Additional slides as needed -->
          <div class="carousel-slide">
            <div style="display: flex; flex-direction: column; justify-content: center; align-items: center; height: 100%;">
              <img src="static/images/tabular_regression.png" alt="MY ALT TEXT"/>
              <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
                LIFT for <b>Tabular Regression</b>
              </h2>
            </div>
          </div>
        </div>
      </div>
  
  <!-- Navigation dots -->
  <div class="carousel-nav">
      <span class="dot active"></span>
      <span class="dot"></span>
      <!-- Add more dots as needed -->
      </div>
    </div>
  </div>
</section>

<!-- Image carousel -->
<section class="hero is-small" id="tasks">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">One Model, Many Tasks</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/tabular_regression.png" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
          LIFT for <b>Tabular Regression</b>
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/tabular_classification.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
          LIFT for <b>Tabular Classification</b>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/image_classification.jpg" alt="MY ALT TEXT"/>
        <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
          LIFT for <b>Image Classification</b>
       </h2>
     </div>
     <div class="item">
      <!-- Your image here -->
      <img src="static/images/image_generation.jpg" alt="MY ALT TEXT"/>
      <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
        LIFT for <b>Image Generation</b>
     </h2>
   </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->

<section class="hero is-small is-light" id="comparison">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Language-Interfaced Learning: Fine-Tuning versus In-Context Learning</h2>
      
      <canvas id="comparisonChart"></canvas>
      
      
      <h2 class="subtitle has-text-centered" style="margin-top: 1rem;">
        Comparison of accuracies between ICL and fine-tuning with LIFT on OpenML datasets.
      </h2>
      <p>
        "LIFT/Full-Data" and "LIFT/Subset" represent LIFT on the full dataset and its subset used correspondingly in the ICL setting (number of prompts). Here, the size of the subset is chosen to satisfy the LMs' context length. Overall, LIFT/GPTs on full data achieve the best performances. However, when using the same number of samples, LIFT and ICL are more comparable in most cases. Note that both methods may be worse than MCC due to the limited training data in some cases.
      </p>
    </div>
  </div>
</section>

<section class="hero is-small is-light" id="performance">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <h2 class="title is-3">Model Performance Comparison Heatmap - OpenML Datasets</h2>
          
          <div class="heatmap-container" id="heatmapContainer">
              <!-- Heatmap will be inserted here -->
          </div>
          
          <div class="legend">
              <span>0%</span>
              <div class="legend-gradient"></div>
              <span>100%</span>
          </div>

          <h2 class="subtitle has-text-centered">
              Heatmap of model performances across OpenML datasets
          </h2>
          <p class="content">
              The heatmap shows performance comparisons between different models across various OpenML datasets. 
              Darker blue indicates higher accuracy. Hover over cells to see exact accuracy values and standard deviations.
          </p>
      </div>
  </div>
</section>

<section class="hero is-small" id="key-points">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Building on Our Research: Spotlights</h2>
      
      <div class="columns is-centered">
        <div class="column is-10">
          <!-- First point -->
          <div class="box highlight-box">
            <div class="columns is-vcentered">
              <div class="column is-1">
                <span class="icon is-large has-text-primary">
                  <i class="fas fa-flask fa-2x"></i>
                </span>
              </div>
              <div class="column">
                <div class="highlight-content">
                  <span class="highlight-title">Predictive Chemistry</span>
                  <p>Leveraging large language models for predictive chemistry. <a href="https://www.nature.com/articles/s42256-023-00788-1">Learn more</a></p>
                </div>
              </div>
            </div>
          </div>

          <!-- Second point -->
          <div class="box highlight-box">
            <div class="columns is-vcentered">
              <div class="column is-1">
                <span class="icon is-large has-text-primary">
                  <i class="fas fa-chart-line fa-2x"></i>
                </span>
              </div>
              <div class="column">
                <div class="highlight-content">
                  <span class="highlight-title">Competitive Performance</span>
                  <p>Achieves comparable results to specialized models across various classification and regression tasks.</p>
                </div>
              </div>
            </div>
          </div>

          <!-- Third point -->
          <div class="box highlight-box">
            <div class="columns is-vcentered">
              <div class="column is-1">
                <span class="icon is-large has-text-primary">
                  <i class="fas fa-brain fa-2x"></i>
                </span>
              </div>
              <div class="column">
                <div class="highlight-content">
                  <span class="highlight-title">Versatile Applications</span>
                  <p>Successfully handles diverse tasks from tabular data to image classification through language-based interfaces.</p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Paper poster -->
<section class="hero is-small is-light" id="poster">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/lift_poster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>
        @inproceedings{tuan_zeng_2022_lift,
          author = {Dinh, Tuan and Zeng, Yuchen and Zhang, Ruisu and Lin, Ziqian and Gira, Michael and Rajput, Shashank and Sohn, Jy-yong and Papailiopoulos, Dimitris and Lee, Kangwook},
          booktitle = {Advances in Neural Information Processing Systems},
          pages = {11763--11784},
          title = {LIFT: Language-Interfaced Fine-Tuning for Non-language Machine Learning Tasks},
          volume = {35},
          year = {2022}
         }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
